{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8I0tL15SUR9n"
      },
      "outputs": [],
      "source": [
        "# !ssh davandenakker@login.delftblue.tudelft.nl"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BL7YHPShREPc"
      },
      "source": [
        "#RNN seq2seq PROGRAM"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DlhkzI8gzvBZ"
      },
      "source": [
        "## Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyq1SJeWzcX_",
        "outputId": "889a3714-2dcc-455e-e33f-a5d0cf1c1afe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to C:\\Users\\Adrian\n",
            "[nltk_data]     Segura\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rPeyPaFkwkeh"
      },
      "source": [
        "Clone the KQA Pro repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9JhHXERvSbv",
        "outputId": "aa5c7b2a-c389-49c1-ccd8-485122001c29"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'KQAPro_Baselines' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/shijx12/KQAPro_Baselines.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptiPWuaa4uqV",
        "outputId": "a972382d-4906-481c-c52d-be978eef9dee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WinError 2] The system cannot find the file specified: 'KQAPro_Baselines'\n",
            "c:\\Users\\Adrian Segura\\Desktop\\TUDelft\\Q4\\KQAPro_Baselines\n"
          ]
        }
      ],
      "source": [
        "cd KQAPro_Baselines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTcAXPcBI2qT",
        "outputId": "748dbb48-a9c7-45a9-8c74-1ed005c05cca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in c:\\users\\adrian segura\\anaconda3\\lib\\site-packages (4.64.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\adrian segura\\appdata\\roaming\\python\\python39\\site-packages (from tqdm) (0.4.4)\n",
            "\n",
            "[notice] A new release of pip available: 22.1.2 -> 23.1.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GnvvNmZKdgB2"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "import os\n",
        "from tqdm import tqdm, trange\n",
        "import numpy as np\n",
        "import pickle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting certifi\n",
            "  Using cached certifi-2023.5.7-py3-none-any.whl (156 kB)\n",
            "Installing collected packages: certifi\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2021.10.8\n",
            "    Uninstalling certifi-2021.10.8:\n",
            "      Successfully uninstalled certifi-2021.10.8\n",
            "Successfully installed certifi-2023.5.7\n",
            "\n",
            "[notice] A new release of pip available: 22.1.2 -> 23.1.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "conda-repo-cli 1.0.4 requires pathlib, which is not installed.\n"
          ]
        }
      ],
      "source": [
        "pip install --force-reinstall certifi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa3Emkxr1Cpx",
        "outputId": "00a8af6d-db43-4994-95d1-e37d89143f51"
      },
      "outputs": [
        {
          "ename": "URLError",
          "evalue": "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1129)>",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mSSLCertVerificationError\u001b[0m                  Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\Adrian Segura\\anaconda3\\lib\\urllib\\request.py:1346\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1345\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1346\u001b[0m     h\u001b[39m.\u001b[39;49mrequest(req\u001b[39m.\u001b[39;49mget_method(), req\u001b[39m.\u001b[39;49mselector, req\u001b[39m.\u001b[39;49mdata, headers,\n\u001b[0;32m   1347\u001b[0m               encode_chunked\u001b[39m=\u001b[39;49mreq\u001b[39m.\u001b[39;49mhas_header(\u001b[39m'\u001b[39;49m\u001b[39mTransfer-encoding\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[0;32m   1348\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m err: \u001b[39m# timeout error\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Adrian Segura\\anaconda3\\lib\\http\\client.py:1285\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1284\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1285\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_request(method, url, body, headers, encode_chunked)\n",
            "File \u001b[1;32mc:\\Users\\Adrian Segura\\anaconda3\\lib\\http\\client.py:1331\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1330\u001b[0m     body \u001b[39m=\u001b[39m _encode(body, \u001b[39m'\u001b[39m\u001b[39mbody\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 1331\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mendheaders(body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
            "File \u001b[1;32mc:\\Users\\Adrian Segura\\anaconda3\\lib\\http\\client.py:1280\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1279\u001b[0m     \u001b[39mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1280\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_output(message_body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
            "File \u001b[1;32mc:\\Users\\Adrian Segura\\anaconda3\\lib\\http\\client.py:1040\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1039\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1040\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(msg)\n\u001b[0;32m   1042\u001b[0m \u001b[39mif\u001b[39;00m message_body \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1043\u001b[0m \n\u001b[0;32m   1044\u001b[0m     \u001b[39m# create a consistent interface to message_body\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Adrian Segura\\anaconda3\\lib\\http\\client.py:980\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    979\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_open:\n\u001b[1;32m--> 980\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnect()\n\u001b[0;32m    981\u001b[0m \u001b[39melse\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\Adrian Segura\\anaconda3\\lib\\http\\client.py:1454\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1452\u001b[0m     server_hostname \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost\n\u001b[1;32m-> 1454\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_context\u001b[39m.\u001b[39;49mwrap_socket(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msock,\n\u001b[0;32m   1455\u001b[0m                                       server_hostname\u001b[39m=\u001b[39;49mserver_hostname)\n",
            "File \u001b[1;32mc:\\Users\\Adrian Segura\\anaconda3\\lib\\ssl.py:500\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrap_socket\u001b[39m(\u001b[39mself\u001b[39m, sock, server_side\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    495\u001b[0m                 do_handshake_on_connect\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    496\u001b[0m                 suppress_ragged_eofs\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    497\u001b[0m                 server_hostname\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, session\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    498\u001b[0m     \u001b[39m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[0;32m    499\u001b[0m     \u001b[39m# ctx._wrap_socket()\u001b[39;00m\n\u001b[1;32m--> 500\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msslsocket_class\u001b[39m.\u001b[39;49m_create(\n\u001b[0;32m    501\u001b[0m         sock\u001b[39m=\u001b[39;49msock,\n\u001b[0;32m    502\u001b[0m         server_side\u001b[39m=\u001b[39;49mserver_side,\n\u001b[0;32m    503\u001b[0m         do_handshake_on_connect\u001b[39m=\u001b[39;49mdo_handshake_on_connect,\n\u001b[0;32m    504\u001b[0m         suppress_ragged_eofs\u001b[39m=\u001b[39;49msuppress_ragged_eofs,\n\u001b[0;32m    505\u001b[0m         server_hostname\u001b[39m=\u001b[39;49mserver_hostname,\n\u001b[0;32m    506\u001b[0m         context\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    507\u001b[0m         session\u001b[39m=\u001b[39;49msession\n\u001b[0;32m    508\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\Adrian Segura\\anaconda3\\lib\\ssl.py:1040\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1039\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1040\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_handshake()\n\u001b[0;32m   1041\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mOSError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n",
            "File \u001b[1;32mc:\\Users\\Adrian Segura\\anaconda3\\lib\\ssl.py:1309\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1308\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msettimeout(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m-> 1309\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mdo_handshake()\n\u001b[0;32m   1310\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
            "\u001b[1;31mSSLCertVerificationError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1129)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[8], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m   os\u001b[39m.\u001b[39mremove(zip_file_path)\n\u001b[0;32m      9\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFinished downloading and extracting\u001b[39m\u001b[39m\"\u001b[39m, path)\n\u001b[1;32m---> 11\u001b[0m download_and_unzip(\n\u001b[0;32m     12\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mhttps://cloud.tsinghua.edu.cn/f/04ce81541e704a648b03/?dl=1\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     13\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39m./dataset\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     15\u001b[0m download_and_unzip(\n\u001b[0;32m     16\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mhttp://nlp.stanford.edu/data/glove.840B.300d.zip\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     17\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m./glove\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     18\u001b[0m )\n",
            "Cell \u001b[1;32mIn[8], line 3\u001b[0m, in \u001b[0;36mdownload_and_unzip\u001b[1;34m(url, path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdownload_and_unzip\u001b[39m(url, path):\n\u001b[0;32m      2\u001b[0m   zip_file_path \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m.zip\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m   urllib\u001b[39m.\u001b[39;49mrequest\u001b[39m.\u001b[39;49murlretrieve(url, zip_file_path)\n\u001b[0;32m      4\u001b[0m   \u001b[39m# Path to extract the contents of the zip file\u001b[39;00m\n\u001b[0;32m      5\u001b[0m   \u001b[39m# Extract the zip file\u001b[39;00m\n\u001b[0;32m      6\u001b[0m   \u001b[39mwith\u001b[39;00m zipfile\u001b[39m.\u001b[39mZipFile(zip_file_path, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m zip_ref:\n",
            "File \u001b[1;32mc:\\Users\\Adrian Segura\\anaconda3\\lib\\urllib\\request.py:239\u001b[0m, in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    223\u001b[0m \u001b[39mRetrieve a URL into a temporary location on disk.\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[39mdata file as well as the resulting HTTPMessage object.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    237\u001b[0m url_type, path \u001b[39m=\u001b[39m _splittype(url)\n\u001b[1;32m--> 239\u001b[0m \u001b[39mwith\u001b[39;00m contextlib\u001b[39m.\u001b[39mclosing(urlopen(url, data)) \u001b[39mas\u001b[39;00m fp:\n\u001b[0;32m    240\u001b[0m     headers \u001b[39m=\u001b[39m fp\u001b[39m.\u001b[39minfo()\n\u001b[0;32m    242\u001b[0m     \u001b[39m# Just return the local path and the \"headers\" for file://\u001b[39;00m\n\u001b[0;32m    243\u001b[0m     \u001b[39m# URLs. No sense in performing a copy unless requested.\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Adrian Segura\\anaconda3\\lib\\urllib\\request.py:214\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m     opener \u001b[39m=\u001b[39m _opener\n\u001b[1;32m--> 214\u001b[0m \u001b[39mreturn\u001b[39;00m opener\u001b[39m.\u001b[39;49mopen(url, data, timeout)\n",
            "File \u001b[1;32mc:\\Users\\Adrian Segura\\anaconda3\\lib\\urllib\\request.py:517\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    514\u001b[0m     req \u001b[39m=\u001b[39m meth(req)\n\u001b[0;32m    516\u001b[0m sys\u001b[39m.\u001b[39maudit(\u001b[39m'\u001b[39m\u001b[39murllib.Request\u001b[39m\u001b[39m'\u001b[39m, req\u001b[39m.\u001b[39mfull_url, req\u001b[39m.\u001b[39mdata, req\u001b[39m.\u001b[39mheaders, req\u001b[39m.\u001b[39mget_method())\n\u001b[1;32m--> 517\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open(req, data)\n\u001b[0;32m    519\u001b[0m \u001b[39m# post-process response\u001b[39;00m\n\u001b[0;32m    520\u001b[0m meth_name \u001b[39m=\u001b[39m protocol\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_response\u001b[39m\u001b[39m\"\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\Adrian Segura\\anaconda3\\lib\\urllib\\request.py:534\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    531\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m    533\u001b[0m protocol \u001b[39m=\u001b[39m req\u001b[39m.\u001b[39mtype\n\u001b[1;32m--> 534\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_chain(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle_open, protocol, protocol \u001b[39m+\u001b[39;49m\n\u001b[0;32m    535\u001b[0m                           \u001b[39m'\u001b[39;49m\u001b[39m_open\u001b[39;49m\u001b[39m'\u001b[39;49m, req)\n\u001b[0;32m    536\u001b[0m \u001b[39mif\u001b[39;00m result:\n\u001b[0;32m    537\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
            "File \u001b[1;32mc:\\Users\\Adrian Segura\\anaconda3\\lib\\urllib\\request.py:494\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[39mfor\u001b[39;00m handler \u001b[39min\u001b[39;00m handlers:\n\u001b[0;32m    493\u001b[0m     func \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 494\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    495\u001b[0m     \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    496\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n",
            "File \u001b[1;32mc:\\Users\\Adrian Segura\\anaconda3\\lib\\urllib\\request.py:1389\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1388\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhttps_open\u001b[39m(\u001b[39mself\u001b[39m, req):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_open(http\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mHTTPSConnection, req,\n\u001b[0;32m   1390\u001b[0m         context\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_context, check_hostname\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_hostname)\n",
            "File \u001b[1;32mc:\\Users\\Adrian Segura\\anaconda3\\lib\\urllib\\request.py:1349\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m         h\u001b[39m.\u001b[39mrequest(req\u001b[39m.\u001b[39mget_method(), req\u001b[39m.\u001b[39mselector, req\u001b[39m.\u001b[39mdata, headers,\n\u001b[0;32m   1347\u001b[0m                   encode_chunked\u001b[39m=\u001b[39mreq\u001b[39m.\u001b[39mhas_header(\u001b[39m'\u001b[39m\u001b[39mTransfer-encoding\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m   1348\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m err: \u001b[39m# timeout error\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m         \u001b[39mraise\u001b[39;00m URLError(err)\n\u001b[0;32m   1350\u001b[0m     r \u001b[39m=\u001b[39m h\u001b[39m.\u001b[39mgetresponse()\n\u001b[0;32m   1351\u001b[0m \u001b[39mexcept\u001b[39;00m:\n",
            "\u001b[1;31mURLError\u001b[0m: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1129)>"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "def download_and_unzip(url, path):\n",
        "  zip_file_path = f\"{path}.zip\"\n",
        "  urllib.request.urlretrieve(url, zip_file_path)\n",
        "  # Path to extract the contents of the zip file\n",
        "  # Extract the zip file\n",
        "  with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "      zip_ref.extractall(path)\n",
        "  os.remove(zip_file_path)\n",
        "  print(\"Finished downloading and extracting\", path)\n",
        "\n",
        "download_and_unzip(\n",
        "    \"https://cloud.tsinghua.edu.cn/f/04ce81541e704a648b03/?dl=1\",\n",
        "    \"./dataset\"\n",
        ")\n",
        "download_and_unzip(\n",
        "    \"http://nlp.stanford.edu/data/glove.840B.300d.zip\",\n",
        "    \"./glove\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Adrian Segura\\Desktop\\TUDelft\\Q4\\KQAPro_Baselines\n"
          ]
        }
      ],
      "source": [
        "cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9a00KQHGyPj",
        "outputId": "c011ae3f-ee0a-488b-ec6d-41b555c25aa4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2196017it [03:42, 9852.15it/s] \n"
          ]
        }
      ],
      "source": [
        "chunk_size = 100000  # Number of entries per chunk\n",
        "chunk_index = 0\n",
        "\n",
        "res = {}\n",
        "ctr = 0\n",
        "for line in tqdm(open(\"./glove/glove.840B.300d.txt\", encoding=\"latin-1\")):\n",
        "    word, *vec = line.split()\n",
        "    try:\n",
        "        vec = np.asarray(list(map(float, vec)))\n",
        "        res[word] = vec\n",
        "    except Exception as e:\n",
        "        pass\n",
        "\n",
        "    # Save the dictionary in chunks\n",
        "    if len(res) >= chunk_size:\n",
        "        with open(f\"./glove/glove_{chunk_index}.pkl\", 'wb') as f:\n",
        "            pickle.dump(res, f)\n",
        "        res = {}\n",
        "        chunk_index += 1\n",
        "\n",
        "# Save the remaining entries in the last chunk\n",
        "if len(res) > 0:\n",
        "    with open(f\"./glove/glove_{chunk_index}.pkl\", 'wb') as f:\n",
        "        pickle.dump(res, f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "del res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-dli1bcR8aD",
        "outputId": "ede13eeb-04b4-482d-fb10-ba362e330de9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 22/22 [00:18<00:00,  1.17it/s]\n"
          ]
        }
      ],
      "source": [
        "merged_res = {}\n",
        "for i in trange(chunk_index + 1):\n",
        "    with open(f\"./glove/glove_{i}.pkl\", 'rb') as f:\n",
        "        chunk_dict = pickle.load(f)\n",
        "    merged_res.update(chunk_dict)\n",
        "\n",
        "# Save the merged dictionary to a single file\n",
        "with open(\"./glove/glove_merged.pkl\", 'wb') as f:\n",
        "    pickle.dump(merged_res, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "15kKbAWdQOlH"
      },
      "outputs": [],
      "source": [
        "# delete chunks\n",
        "for i in range(chunk_index + 1):\n",
        "    file_path = f\"./glove/glove_{i}.pkl\"\n",
        "    if os.path.exists(file_path):\n",
        "        os.remove(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccXLeiupQfRs",
        "outputId": "fab6bbba-d363-4319-c906-c68dd74380cc"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[21], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m line_count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(file_path, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlatin-1\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[1;32m----> 5\u001b[0m     \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m file:\n\u001b[0;32m      6\u001b[0m         line_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNumber of lines:\u001b[39m\u001b[39m\"\u001b[39m, line_count)\n",
            "File \u001b[1;32mc:\\Users\\Adrian Segura\\anaconda3\\lib\\encodings\\latin_1.py:25\u001b[0m, in \u001b[0;36mIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mIncrementalDecoder\u001b[39;00m(codecs\u001b[39m.\u001b[39mIncrementalDecoder):\n\u001b[1;32m---> 25\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m     26\u001b[0m         \u001b[39mreturn\u001b[39;00m codecs\u001b[39m.\u001b[39mlatin_1_decode(\u001b[39minput\u001b[39m,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39merrors)[\u001b[39m0\u001b[39m]\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "file_path = \"./glove/glove.840B.300d.txt\"\n",
        "line_count = 0\n",
        "\n",
        "with open(file_path, 'r', encoding='latin-1') as file:\n",
        "    for line in file:\n",
        "        line_count += 1\n",
        "\n",
        "print(\"Number of lines:\", line_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuUJuZLQM4j6",
        "outputId": "e772feed-0b2e-42ad-df37-2e8c94ad107a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "glove.840B.300d.txt  glove.pkl\n"
          ]
        }
      ],
      "source": [
        "ls ./glove/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFM3QCbGdUrw",
        "outputId": "7db66b16-fbe7-4416-9bfa-8c0f8d2194a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2196017it [03:52, 9442.29it/s]\n",
            "/bin/bash: line 1: 13374 Killed                  python -m utils.pickle_glove --input ./glove/glove.840B.300d.txt --output ./glove/glove.pkl >> ignore.txt\n"
          ]
        }
      ],
      "source": [
        "!python -m utils.pickle_glove --input ./glove/glove.840B.300d.txt --output ./glove/glove.pkl >> ignore.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieving notices: ...working... done\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "EnvironmentLocationNotFound: Not a conda environment: c:\\Users\\Adrian\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "conda install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQO0vyPpaMjU",
        "outputId": "43e2018d-4c43-425f-cc54-67f905f9e67e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load questions\n",
            "Build question vocabulary\n",
            "Dump vocab to ./processed/vocab.json\n",
            "word_token_to_idx:80201\n",
            "function_token_to_idx:31\n",
            "answer_token_to_idx:81629\n",
            "Encode train set\n",
            "shape of questions, functions, func_depends, func_inputs, choices, answers:\n",
            "(94376, 85)\n",
            "(94376, 17)\n",
            "(94376, 17, 2)\n",
            "(94376, 17, 3)\n",
            "(94376, 10)\n",
            "(94376,)\n",
            "Encode val set\n",
            "shape of questions, functions, func_depends, func_inputs, choices, answers:\n",
            "(11797, 61)\n",
            "(11797, 16)\n",
            "(11797, 16, 2)\n",
            "(11797, 16, 3)\n",
            "(11797, 10)\n",
            "(11797,)\n",
            "Encode test set\n",
            "shape of questions, functions, func_depends, func_inputs, choices, answers:\n",
            "(11797, 51)\n",
            "(0,)\n",
            "(0,)\n",
            "(0,)\n",
            "(11797, 10)\n",
            "(0,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/94376 [00:00<?, ?it/s]\n",
            "  1%|          | 945/94376 [00:00<00:09, 9441.12it/s]\n",
            "  2%|▏         | 1899/94376 [00:00<00:09, 9494.18it/s]\n",
            "  3%|▎         | 2849/94376 [00:00<00:09, 9158.18it/s]\n",
            "  4%|▍         | 3782/94376 [00:00<00:09, 9221.14it/s]\n",
            "  5%|▍         | 4706/94376 [00:00<00:10, 8908.16it/s]\n",
            "  6%|▌         | 5599/94376 [00:00<00:10, 8768.38it/s]\n",
            "  7%|▋         | 6481/94376 [00:00<00:10, 8782.15it/s]\n",
            "  8%|▊         | 7361/94376 [00:00<00:10, 8545.90it/s]\n",
            "  9%|▊         | 8234/94376 [00:00<00:10, 8599.09it/s]\n",
            " 10%|▉         | 9096/94376 [00:01<00:09, 8551.50it/s]\n",
            " 11%|█         | 9952/94376 [00:01<00:24, 3477.21it/s]\n",
            " 12%|█▏        | 10882/94376 [00:01<00:19, 4339.24it/s]\n",
            " 12%|█▏        | 11695/94376 [00:01<00:16, 5000.50it/s]\n",
            " 13%|█▎        | 12572/94376 [00:01<00:14, 5752.04it/s]\n",
            " 14%|█▍        | 13463/94376 [00:02<00:12, 6451.47it/s]\n",
            " 15%|█▌        | 14385/94376 [00:02<00:11, 7116.19it/s]\n",
            " 16%|█▌        | 15272/94376 [00:02<00:10, 7563.04it/s]\n",
            " 17%|█▋        | 16187/94376 [00:02<00:09, 7985.74it/s]\n",
            " 18%|█▊        | 17065/94376 [00:02<00:09, 8180.63it/s]\n",
            " 19%|█▉        | 17963/94376 [00:02<00:09, 8404.35it/s]\n",
            " 20%|█▉        | 18845/94376 [00:02<00:08, 8497.18it/s]\n",
            " 21%|██        | 19754/94376 [00:02<00:08, 8667.10it/s]\n",
            " 22%|██▏       | 20642/94376 [00:02<00:08, 8676.29it/s]\n",
            " 23%|██▎       | 21525/94376 [00:02<00:08, 8719.13it/s]\n",
            " 24%|██▎       | 22408/94376 [00:03<00:08, 8698.11it/s]\n",
            " 25%|██▍       | 23328/94376 [00:03<00:08, 8844.14it/s]\n",
            " 26%|██▌       | 24258/94376 [00:03<00:07, 8977.05it/s]\n",
            " 27%|██▋       | 25160/94376 [00:03<00:07, 8987.42it/s]\n",
            " 28%|██▊       | 26073/94376 [00:03<00:07, 9027.52it/s]\n",
            " 29%|██▊       | 26978/94376 [00:03<00:07, 9004.87it/s]\n",
            " 30%|██▉       | 27880/94376 [00:03<00:07, 8953.46it/s]\n",
            " 31%|███       | 28788/94376 [00:03<00:07, 8988.65it/s]\n",
            " 31%|███▏      | 29722/94376 [00:03<00:07, 9091.02it/s]\n",
            " 32%|███▏      | 30662/94376 [00:03<00:06, 9180.83it/s]\n",
            " 33%|███▎      | 31581/94376 [00:04<00:06, 9099.38it/s]\n",
            " 34%|███▍      | 32492/94376 [00:04<00:06, 9100.07it/s]\n",
            " 35%|███▌      | 33403/94376 [00:04<00:06, 9100.57it/s]\n",
            " 36%|███▋      | 34322/94376 [00:04<00:06, 9124.82it/s]\n",
            " 37%|███▋      | 35240/94376 [00:04<00:06, 9138.84it/s]\n",
            " 38%|███▊      | 36155/94376 [00:04<00:06, 9112.42it/s]\n",
            " 39%|███▉      | 37072/94376 [00:04<00:06, 9127.12it/s]\n",
            " 40%|████      | 37985/94376 [00:04<00:06, 9017.57it/s]\n",
            " 41%|████      | 38888/94376 [00:04<00:06, 9018.82it/s]\n",
            " 42%|████▏     | 39791/94376 [00:04<00:06, 8913.51it/s]\n",
            " 43%|████▎     | 40683/94376 [00:05<00:06, 8757.44it/s]\n",
            " 44%|████▍     | 41570/94376 [00:05<00:06, 8788.14it/s]\n",
            " 45%|████▌     | 42485/94376 [00:05<00:05, 8892.58it/s]\n",
            " 46%|████▌     | 43401/94376 [00:05<00:05, 8969.50it/s]\n",
            " 47%|████▋     | 44307/94376 [00:05<00:05, 8994.01it/s]\n",
            " 48%|████▊     | 45207/94376 [00:05<00:05, 8783.64it/s]\n",
            " 49%|████▉     | 46097/94376 [00:05<00:05, 8815.49it/s]\n",
            " 50%|████▉     | 46980/94376 [00:05<00:05, 8739.84it/s]\n",
            " 51%|█████     | 47875/94376 [00:05<00:05, 8786.07it/s]\n",
            " 52%|█████▏    | 48755/94376 [00:05<00:05, 8761.74it/s]\n",
            " 53%|█████▎    | 49648/94376 [00:06<00:05, 8809.31it/s]\n",
            " 54%|█████▎    | 50530/94376 [00:06<00:13, 3324.88it/s]\n",
            " 54%|█████▍    | 51419/94376 [00:06<00:10, 4093.81it/s]\n",
            " 55%|█████▌    | 52322/94376 [00:06<00:08, 4906.95it/s]\n",
            " 56%|█████▋    | 53176/94376 [00:07<00:07, 5598.49it/s]\n",
            " 57%|█████▋    | 54098/94376 [00:07<00:06, 6372.24it/s]\n",
            " 58%|█████▊    | 55013/94376 [00:07<00:05, 7021.01it/s]\n",
            " 59%|█████▉    | 55900/94376 [00:07<00:05, 7482.63it/s]\n",
            " 60%|██████    | 56807/94376 [00:07<00:04, 7899.10it/s]\n",
            " 61%|██████    | 57705/94376 [00:07<00:04, 8192.67it/s]\n",
            " 62%|██████▏   | 58590/94376 [00:07<00:04, 8375.18it/s]\n",
            " 63%|██████▎   | 59513/94376 [00:07<00:04, 8598.79it/s]\n",
            " 64%|██████▍   | 60407/94376 [00:07<00:03, 8695.39it/s]\n",
            " 65%|██████▍   | 61303/94376 [00:07<00:03, 8770.50it/s]\n",
            " 66%|██████▌   | 62198/94376 [00:08<00:03, 8795.12it/s]\n",
            " 67%|██████▋   | 63121/94376 [00:08<00:03, 8921.29it/s]\n",
            " 68%|██████▊   | 64032/94376 [00:08<00:03, 8974.83it/s]\n",
            " 69%|██████▉   | 64954/94376 [00:08<00:03, 9045.11it/s]\n",
            " 70%|██████▉   | 65863/94376 [00:08<00:03, 9004.33it/s]\n",
            " 71%|███████   | 66767/94376 [00:08<00:03, 9012.42it/s]\n",
            " 72%|███████▏  | 67671/94376 [00:08<00:02, 9018.20it/s]\n",
            " 73%|███████▎  | 68586/94376 [00:08<00:02, 9054.60it/s]\n",
            " 74%|███████▎  | 69493/94376 [00:08<00:02, 8992.03it/s]\n",
            " 75%|███████▍  | 70394/94376 [00:08<00:02, 8968.25it/s]\n",
            " 76%|███████▌  | 71292/94376 [00:09<00:02, 8969.29it/s]\n",
            " 77%|███████▋  | 72221/94376 [00:09<00:02, 9062.54it/s]\n",
            " 77%|███████▋  | 73130/94376 [00:09<00:02, 9068.28it/s]\n",
            " 78%|███████▊  | 74040/94376 [00:09<00:02, 9075.32it/s]\n",
            " 79%|███████▉  | 74953/94376 [00:09<00:02, 9089.17it/s]\n",
            " 80%|████████  | 75881/94376 [00:09<00:02, 9143.83it/s]\n",
            " 81%|████████▏ | 76796/94376 [00:09<00:01, 9088.73it/s]\n",
            " 82%|████████▏ | 77706/94376 [00:09<00:01, 9062.55it/s]\n",
            " 83%|████████▎ | 78613/94376 [00:09<00:01, 9008.57it/s]\n",
            " 84%|████████▍ | 79514/94376 [00:09<00:01, 8979.85it/s]\n",
            " 85%|████████▌ | 80413/94376 [00:10<00:01, 8980.44it/s]\n",
            " 86%|████████▌ | 81329/94376 [00:10<00:01, 9031.54it/s]\n",
            " 87%|████████▋ | 82233/94376 [00:10<00:01, 9031.61it/s]\n",
            " 88%|████████▊ | 83170/94376 [00:10<00:01, 9130.32it/s]\n",
            " 89%|████████▉ | 84087/94376 [00:10<00:01, 9139.67it/s]\n",
            " 90%|█████████ | 85002/94376 [00:10<00:01, 9112.98it/s]\n",
            " 91%|█████████ | 85914/94376 [00:10<00:00, 9112.61it/s]\n",
            " 92%|█████████▏| 86826/94376 [00:10<00:00, 9112.37it/s]\n",
            " 93%|█████████▎| 87738/94376 [00:10<00:00, 9112.15it/s]\n",
            " 94%|█████████▍| 88650/94376 [00:10<00:00, 9084.79it/s]\n",
            " 95%|█████████▍| 89561/94376 [00:11<00:00, 9089.86it/s]\n",
            " 96%|█████████▌| 90477/94376 [00:11<00:00, 9108.37it/s]\n",
            " 97%|█████████▋| 91405/94376 [00:11<00:00, 9157.26it/s]\n",
            " 98%|█████████▊| 92330/94376 [00:11<00:00, 9182.51it/s]\n",
            " 99%|█████████▉| 93252/94376 [00:11<00:00, 9191.31it/s]\n",
            "100%|█████████▉| 94172/94376 [00:11<00:00, 9136.61it/s]\n",
            "100%|██████████| 94376/94376 [00:11<00:00, 8161.04it/s]\n",
            "\n",
            "  0%|          | 0/11797 [00:00<?, ?it/s]\n",
            "  8%|▊         | 887/11797 [00:00<00:01, 8861.98it/s]\n",
            " 15%|█▌        | 1806/11797 [00:00<00:01, 9049.98it/s]\n",
            " 23%|██▎       | 2729/11797 [00:00<00:00, 9128.34it/s]\n",
            " 31%|███       | 3658/11797 [00:00<00:00, 9188.87it/s]\n",
            " 39%|███▉      | 4577/11797 [00:00<00:00, 9186.25it/s]\n",
            " 47%|████▋     | 5496/11797 [00:00<00:00, 9184.66it/s]\n",
            " 54%|█████▍    | 6415/11797 [00:00<00:00, 9124.02it/s]\n",
            " 62%|██████▏   | 7340/11797 [00:00<00:00, 9161.33it/s]\n",
            " 70%|██████▉   | 8257/11797 [00:01<00:00, 3594.19it/s]\n",
            " 78%|███████▊  | 9163/11797 [00:01<00:00, 4405.72it/s]\n",
            " 85%|████████▌ | 10086/11797 [00:01<00:00, 5249.51it/s]\n",
            " 93%|█████████▎| 10982/11797 [00:01<00:00, 5990.68it/s]\n",
            "100%|██████████| 11797/11797 [00:01<00:00, 6591.89it/s]\n",
            "\n",
            "  0%|          | 0/11797 [00:00<?, ?it/s]\n",
            "  8%|▊         | 969/11797 [00:00<00:01, 9681.33it/s]\n",
            " 17%|█▋        | 1963/11797 [00:00<00:01, 9828.06it/s]\n",
            " 25%|██▍       | 2946/11797 [00:00<00:00, 9605.59it/s]\n",
            " 33%|███▎      | 3937/11797 [00:00<00:00, 9720.62it/s]\n",
            " 42%|████▏     | 4949/11797 [00:00<00:00, 9860.12it/s]\n",
            " 50%|█████     | 5936/11797 [00:00<00:00, 9761.46it/s]\n",
            " 59%|█████▊    | 6920/11797 [00:00<00:00, 9783.95it/s]\n",
            " 67%|██████▋   | 7941/11797 [00:00<00:00, 9915.70it/s]\n",
            " 76%|███████▌  | 8933/11797 [00:00<00:00, 9914.19it/s]\n",
            " 84%|████████▍ | 9945/11797 [00:01<00:00, 9974.70it/s]\n",
            " 93%|█████████▎| 10972/11797 [00:01<00:00, 10062.04it/s]\n",
            "100%|██████████| 11797/11797 [00:01<00:00, 9912.78it/s] \n"
          ]
        }
      ],
      "source": [
        "!python -m Program.preprocess --input_dir ./dataset/KQAPro.IID/ --output_dir ./processed/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "oJl3VxmS0-Ay"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (4175002378.py, line 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;36m  Cell \u001b[1;32mIn[27], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    mv ./dataset/KQAPro.IID/kb.json ./processed/\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "mv ./dataset/KQAPro.IID/kb.json ./processed/"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "71qGilnJwx8p"
      },
      "source": [
        "### train baselines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "9tYe0nHy4UE8",
        "outputId": "cde33c57-ec6c-44a3-ad3a-e3417acfc72f"
      },
      "outputs": [
        {
          "ename": "MessageError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-7f607d3156f6>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# mount glove\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/TUDelft/Q4/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    130\u001b[0m   )\n\u001b[1;32m    131\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "# # mount glove\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive/TUDelft/Q4/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDGHNvre_zeO",
        "outputId": "a76e1e70-fb08-4d27-997d-d22f2ab8583d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "InstanceOf pairs in the concepts dictionary:\n"
          ]
        }
      ],
      "source": [
        "# fix kb key error KeyError: 'predicate'\n",
        "import json\n",
        "# Load the JSON file\n",
        "with open(\"./processed/kb.json\", \"r\") as file:\n",
        "    kb_data = json.load(file)\n",
        "\n",
        "# Print the first element\n",
        "if len(kb_data) > 0:\n",
        "\n",
        "    for ent_id in kb_data['entities']:\n",
        "        for rel_info in kb_data['entities'][ent_id]['relations']:\n",
        "            rel_info['predicate'] = None\n",
        "\n",
        "\n",
        "\n",
        "    # Print the \"instanceOf\" pairs in the concepts dictionary\n",
        "    print(\"InstanceOf pairs in the concepts dictionary:\")\n",
        "    for key, value in kb_data['concepts'].items():\n",
        "        if \"instanceOf\" not in value:\n",
        "          kb_data['concepts'][key][\"instanceOf\"] = []\n",
        "else:\n",
        "    print(\"The knowledge base is empty.\")\n",
        "\n",
        "with open(\"./processed/kb.json\", \"w\") as file:\n",
        "    json.dump(kb_data, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "c = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from Program import train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_IgE-WZ6UND",
        "outputId": "12c7fe76-f9a3-4d5e-8532-6d17893a5e98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#vocab of word: 80201\n",
            "#vocab of answer: 80257\n",
            "load kb\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([30, 30, 28, 28, 28, 26, 26, 25, 24, 23, 23, 22, 22, 22, 22, 21, 21, 20,\n",
            "        20, 20, 20, 20, 19, 19, 19, 18, 18, 17, 17, 17, 17, 16, 16, 16, 16, 16,\n",
            "        15, 14, 14, 14, 13, 13, 13, 13, 13, 12, 12, 11, 11, 11, 11, 11, 11, 10,\n",
            "        10, 10, 10,  9,  9,  8,  8,  8,  7,  6], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([41, 35, 30, 30, 28, 25, 23, 22, 22, 22, 20, 20, 19, 19, 18, 18, 18, 17,\n",
            "        17, 17, 16, 16, 15, 15, 15, 15, 15, 15, 15, 14, 14, 13, 13, 13, 13, 13,\n",
            "        13, 13, 13, 13, 12, 12, 12, 11, 11, 11, 11, 10, 10, 10,  9,  9,  9,  9,\n",
            "         9,  9,  9,  9,  8,  8,  8,  7,  7,  7], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([34, 31, 31, 28, 28, 28, 27, 26, 26, 25, 25, 24, 23, 23, 22, 22, 22, 21,\n",
            "        21, 21, 20, 20, 20, 19, 19, 19, 18, 18, 18, 18, 17, 17, 17, 17, 17, 16,\n",
            "        16, 16, 16, 16, 16, 16, 16, 15, 14, 14, 14, 14, 14, 14, 13, 12, 12, 11,\n",
            "        11, 11, 11, 10, 10,  9,  9,  9,  7,  7], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([36, 35, 28, 26, 26, 25, 25, 23, 22, 22, 22, 21, 21, 21, 21, 21, 20, 20,\n",
            "        20, 20, 19, 19, 19, 19, 19, 18, 18, 18, 18, 17, 17, 17, 17, 17, 16, 15,\n",
            "        15, 15, 15, 14, 14, 13, 13, 13, 13, 12, 12, 12, 11, 11, 11, 11, 11, 10,\n",
            "        10, 10,  9,  9,  9,  9,  9,  8,  7,  7], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([36, 31, 29, 29, 27, 27, 25, 25, 24, 23, 23, 23, 22, 21, 21, 21, 21, 20,\n",
            "        20, 20, 20, 19, 19, 18, 18, 18, 17, 17, 17, 16, 16, 16, 16, 16, 16, 16,\n",
            "        15, 15, 15, 15, 15, 14, 14, 14, 14, 14, 13, 13, 12, 12, 12, 12, 12, 12,\n",
            "        11, 11, 11, 10, 10, 10, 10,  9,  9,  9], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([40, 32, 30, 30, 27, 26, 26, 25, 25, 24, 23, 23, 23, 22, 22, 22, 20, 20,\n",
            "        20, 20, 20, 20, 19, 19, 18, 18, 17, 17, 17, 17, 17, 17, 16, 16, 16, 16,\n",
            "        15, 15, 15, 14, 14, 14, 13, 13, 13, 13, 13, 12, 12, 12, 11, 11, 11, 11,\n",
            "        11, 10, 10,  9,  9,  9,  9,  9,  8,  5], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([28, 28, 27, 26, 24, 23, 22, 21, 20, 20, 20, 20, 19, 19, 19, 19, 18, 18,\n",
            "        17, 17, 17, 17, 17, 16, 16, 16, 16, 16, 16, 16, 16, 16, 15, 15, 15, 15,\n",
            "        15, 14, 14, 14, 14, 14, 13, 12, 12, 12, 12, 12, 11, 11, 11, 11, 11, 10,\n",
            "        10, 10,  9,  9,  9,  9,  8,  8,  7,  7], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([36, 35, 31, 30, 30, 28, 27, 26, 26, 23, 23, 22, 22, 21, 21, 21, 21, 20,\n",
            "        20, 20, 20, 19, 19, 19, 18, 18, 17, 17, 17, 16, 16, 16, 16, 16, 16, 16,\n",
            "        16, 15, 15, 15, 15, 14, 14, 14, 14, 14, 14, 13, 13, 13, 13, 12, 12, 12,\n",
            "        11, 11, 10, 10, 10,  9,  9,  9,  8,  7], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([31, 30, 30, 29, 26, 26, 23, 23, 23, 22, 22, 21, 20, 20, 20, 18, 18, 18,\n",
            "        17, 17, 17, 17, 16, 16, 16, 16, 15, 15, 15, 15, 14, 14, 14, 14, 14, 13,\n",
            "        13, 13, 13, 12, 12, 12, 12, 11, 11, 11, 11, 11, 11, 11, 10, 10, 10, 10,\n",
            "         9,  9,  9,  9,  9,  8,  8,  8,  7,  6], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([32, 29, 29, 27, 27, 25, 24, 24, 24, 22, 21, 21, 21, 20, 20, 20, 19, 19,\n",
            "        18, 18, 18, 18, 18, 18, 18, 17, 17, 17, 17, 17, 17, 17, 17, 16, 16, 16,\n",
            "        15, 15, 15, 15, 15, 14, 14, 13, 13, 13, 13, 12, 12, 12, 12, 12, 12, 12,\n",
            "        11, 11, 11, 10, 10,  9,  8,  7,  7,  6], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([29, 29, 28, 26, 25, 25, 25, 25, 24, 24, 23, 23, 23, 23, 22, 21, 21, 21,\n",
            "        21, 21, 19, 19, 18, 18, 18, 17, 17, 17, 17, 17, 17, 17, 17, 16, 15, 15,\n",
            "        15, 15, 15, 14, 14, 13, 13, 13, 13, 13, 13, 12, 12, 12, 11, 11, 11, 11,\n",
            "        11, 10, 10, 10,  9,  9,  9,  8,  8,  8], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([33, 32, 32, 32, 29, 27, 26, 26, 24, 23, 22, 21, 21, 21, 20, 19, 19, 19,\n",
            "        18, 18, 18, 18, 17, 17, 17, 17, 17, 17, 16, 16, 16, 16, 16, 16, 16, 16,\n",
            "        15, 15, 14, 14, 14, 14, 13, 13, 13, 13, 12, 12, 12, 12, 11, 11, 11, 11,\n",
            "        11, 11, 10, 10,  9,  9,  8,  7,  7,  6], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([52, 37, 31, 31, 31, 29, 27, 26, 26, 25, 25, 23, 22, 21, 21, 21, 21, 20,\n",
            "        19, 19, 19, 18, 18, 17, 16, 16, 16, 16, 15, 15, 15, 15, 14, 14, 14, 14,\n",
            "        14, 13, 13, 13, 13, 12, 12, 12, 12, 12, 11, 11, 11, 10, 10, 10, 10, 10,\n",
            "         9,  9,  9,  9,  9,  8,  8,  8,  8,  7], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([35, 29, 28, 28, 28, 27, 27, 27, 25, 25, 23, 22, 22, 22, 22, 21, 21, 20,\n",
            "        20, 19, 19, 19, 19, 19, 18, 18, 18, 18, 17, 17, 16, 16, 16, 15, 15, 15,\n",
            "        15, 14, 14, 13, 13, 13, 12, 12, 12, 12, 11, 11, 11, 11, 10, 10, 10, 10,\n",
            "        10, 10,  9,  9,  9,  9,  9,  8,  7,  6], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([30, 29, 27, 26, 26, 26, 25, 25, 25, 25, 24, 23, 23, 23, 22, 21, 21, 20,\n",
            "        20, 20, 19, 19, 19, 19, 18, 18, 18, 18, 18, 17, 17, 16, 16, 16, 16, 16,\n",
            "        16, 15, 15, 15, 14, 14, 14, 13, 13, 13, 13, 12, 12, 11, 11, 11, 11, 10,\n",
            "        10, 10, 10,  9,  9,  9,  9,  8,  8,  7], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([31, 28, 28, 28, 28, 27, 27, 25, 23, 23, 22, 22, 21, 20, 20, 20, 20, 20,\n",
            "        19, 18, 18, 18, 18, 17, 17, 17, 16, 16, 16, 16, 16, 16, 15, 15, 15, 15,\n",
            "        14, 14, 14, 13, 13, 12, 12, 12, 12, 12, 11, 11, 11, 11, 11, 11, 11, 10,\n",
            "        10,  9,  9,  8,  8,  8,  8,  7,  7,  7], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([37, 33, 33, 30, 29, 28, 25, 24, 24, 22, 22, 22, 21, 20, 20, 19, 19, 19,\n",
            "        18, 18, 18, 18, 18, 17, 17, 17, 16, 16, 16, 16, 16, 16, 16, 15, 15, 14,\n",
            "        14, 14, 13, 13, 13, 13, 13, 13, 12, 12, 11, 11, 11, 11, 11, 10, 10, 10,\n",
            "        10,  9,  9,  9,  9,  9,  9,  8,  8,  7], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([39, 32, 28, 27, 25, 25, 23, 23, 22, 22, 21, 21, 20, 20, 20, 19, 19, 19,\n",
            "        19, 19, 19, 18, 18, 18, 18, 17, 17, 17, 17, 17, 17, 17, 16, 16, 15, 15,\n",
            "        15, 14, 14, 13, 13, 13, 12, 12, 12, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
            "        11, 11, 10, 10,  9,  9,  9,  8,  7,  7], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([42, 31, 31, 28, 27, 27, 26, 25, 25, 24, 24, 24, 24, 22, 22, 22, 22, 21,\n",
            "        20, 20, 20, 20, 20, 19, 19, 19, 19, 18, 18, 17, 17, 17, 17, 17, 16, 16,\n",
            "        16, 15, 14, 14, 14, 14, 13, 12, 12, 12, 12, 12, 11, 11, 11, 11, 11, 11,\n",
            "        11, 10, 10, 10, 10, 10,  9,  9,  9,  8], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([39, 33, 33, 31, 31, 30, 29, 26, 25, 25, 25, 25, 25, 25, 24, 24, 24, 23,\n",
            "        23, 23, 21, 21, 21, 21, 21, 21, 20, 19, 18, 18, 18, 18, 17, 17, 17, 17,\n",
            "        16, 16, 16, 16, 15, 15, 15, 15, 14, 13, 13, 13, 12, 12, 12, 11, 11, 11,\n",
            "        10, 10, 10, 10,  9,  9,  9,  7,  7,  7], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([37, 30, 30, 28, 26, 26, 25, 24, 24, 23, 23, 23, 23, 23, 23, 22, 22, 21,\n",
            "        21, 21, 20, 20, 20, 20, 19, 19, 19, 18, 18, 18, 18, 17, 17, 17, 17, 16,\n",
            "        16, 16, 16, 16, 16, 15, 15, 14, 14, 14, 13, 13, 13, 13, 12, 12, 12, 11,\n",
            "        11, 10, 10, 10,  9,  9,  9,  8,  8,  7], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([31, 28, 25, 24, 24, 24, 23, 23, 21, 21, 21, 20, 20, 20, 19, 19, 19, 18,\n",
            "        18, 18, 18, 18, 17, 17, 17, 17, 16, 16, 16, 16, 16, 16, 16, 16, 15, 15,\n",
            "        15, 15, 15, 15, 14, 14, 13, 13, 13, 13, 12, 12, 11, 11, 11, 11, 11, 11,\n",
            "        10, 10, 10, 10,  9,  9,  9,  9,  7,  7], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([35, 30, 29, 27, 26, 25, 25, 25, 25, 24, 24, 23, 22, 22, 22, 21, 21, 20,\n",
            "        20, 19, 18, 18, 17, 17, 16, 16, 15, 15, 15, 15, 15, 15, 14, 14, 14, 14,\n",
            "        14, 14, 14, 14, 13, 13, 13, 13, 12, 12, 12, 12, 12, 12, 12, 11, 11, 11,\n",
            "        10, 10, 10, 10,  9,  9,  9,  8,  8,  6], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([33, 32, 32, 30, 30, 30, 28, 28, 26, 26, 25, 25, 24, 24, 24, 23, 22, 21,\n",
            "        21, 21, 20, 20, 19, 19, 19, 19, 19, 19, 19, 19, 18, 18, 18, 18, 18, 17,\n",
            "        17, 17, 17, 17, 17, 16, 16, 16, 16, 15, 14, 14, 14, 14, 13, 13, 12, 12,\n",
            "        11, 11, 11, 11, 10, 10, 10,  7,  7,  6], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([38, 35, 29, 28, 27, 27, 27, 27, 27, 26, 25, 24, 24, 23, 23, 23, 22, 21,\n",
            "        21, 21, 21, 20, 20, 20, 19, 19, 18, 18, 18, 18, 18, 18, 17, 17, 16, 15,\n",
            "        15, 15, 15, 15, 15, 14, 14, 14, 13, 13, 13, 13, 13, 12, 12, 12, 12, 12,\n",
            "        11, 10, 10, 10, 10,  9,  9,  8,  8,  7], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([38, 33, 32, 31, 29, 29, 28, 27, 27, 26, 26, 25, 25, 24, 24, 24, 23, 23,\n",
            "        22, 22, 20, 20, 20, 20, 20, 19, 18, 18, 17, 17, 17, 16, 16, 16, 16, 15,\n",
            "        15, 15, 15, 15, 14, 14, 14, 14, 14, 14, 13, 13, 13, 12, 12, 11, 11, 11,\n",
            "        11, 11, 11, 10, 10, 10,  9,  9,  9,  6], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([35, 31, 28, 28, 26, 26, 25, 25, 24, 24, 24, 21, 21, 21, 21, 20, 19, 19,\n",
            "        19, 19, 18, 18, 17, 17, 17, 17, 16, 16, 16, 16, 16, 15, 15, 15, 15, 15,\n",
            "        15, 14, 14, 13, 13, 13, 13, 12, 12, 12, 12, 12, 12, 11, 11, 10, 10, 10,\n",
            "         9,  9,  9,  9,  9,  8,  8,  8,  7,  7], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([33, 33, 31, 30, 28, 26, 26, 26, 23, 23, 22, 22, 22, 21, 21, 21, 20, 20,\n",
            "        20, 18, 18, 18, 18, 17, 17, 17, 17, 17, 17, 17, 17, 17, 16, 16, 16, 16,\n",
            "        16, 15, 15, 15, 15, 15, 14, 14, 14, 13, 13, 13, 13, 13, 12, 12, 12, 12,\n",
            "        10, 10, 10, 10, 10, 10,  9,  8,  8,  8], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([41, 34, 31, 31, 31, 29, 28, 28, 27, 27, 27, 26, 24, 24, 24, 23, 23, 23,\n",
            "        23, 22, 21, 20, 19, 19, 19, 19, 18, 18, 18, 18, 17, 17, 16, 16, 16, 16,\n",
            "        15, 15, 15, 15, 14, 14, 14, 14, 14, 13, 13, 12, 12, 12, 11, 11, 11, 11,\n",
            "        11, 11, 10, 10, 10,  9,  9,  9,  8,  7], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([33, 30, 30, 27, 26, 23, 23, 22, 22, 22, 21, 21, 20, 20, 20, 20, 20, 20,\n",
            "        19, 19, 18, 18, 18, 18, 17, 17, 17, 17, 17, 17, 16, 15, 15, 15, 13, 13,\n",
            "        12, 12, 12, 12, 12, 12, 11, 11, 11, 11, 11, 11, 11, 11, 10, 10, 10, 10,\n",
            "        10, 10, 10,  9,  9,  8,  8,  8,  7,  7], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([34, 33, 33, 29, 28, 27, 26, 26, 26, 24, 24, 23, 23, 22, 22, 21, 21, 21,\n",
            "        20, 20, 20, 20, 20, 20, 19, 19, 18, 18, 17, 17, 17, 17, 17, 17, 17, 16,\n",
            "        16, 16, 16, 16, 15, 15, 14, 14, 14, 14, 14, 13, 12, 12, 11, 11, 10, 10,\n",
            "        10,  9,  8,  8,  8,  8,  8,  7,  7,  6], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([33, 31, 30, 27, 26, 26, 25, 25, 23, 23, 23, 22, 22, 22, 22, 21, 20, 19,\n",
            "        19, 19, 18, 18, 18, 18, 17, 17, 16, 16, 16, 16, 16, 16, 16, 15, 15, 15,\n",
            "        15, 15, 15, 14, 14, 13, 13, 13, 13, 13, 13, 12, 12, 12, 11, 11, 11, 11,\n",
            "        11, 10, 10, 10, 10,  9,  9,  9,  8,  7], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([38, 35, 30, 30, 24, 24, 23, 23, 22, 21, 21, 21, 20, 20, 20, 20, 20, 19,\n",
            "        18, 18, 18, 18, 18, 18, 18, 17, 17, 16, 16, 16, 16, 15, 15, 15, 15, 15,\n",
            "        14, 14, 14, 14, 14, 14, 14, 13, 13, 12, 12, 12, 12, 12, 11, 11, 11, 11,\n",
            "        10, 10, 10, 10,  9,  9,  8,  8,  8,  6], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([35, 34, 30, 27, 27, 26, 26, 25, 23, 22, 22, 22, 21, 21, 21, 21, 21, 21,\n",
            "        21, 20, 20, 19, 19, 19, 19, 18, 18, 17, 16, 16, 16, 16, 15, 15, 15, 15,\n",
            "        15, 15, 14, 14, 14, 13, 13, 13, 13, 13, 13, 13, 12, 12, 12, 12, 12, 11,\n",
            "        11, 11, 10, 10, 10, 10, 10,  9,  8,  7], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([36, 33, 31, 30, 26, 25, 24, 24, 24, 24, 23, 23, 22, 22, 21, 21, 20, 20,\n",
            "        20, 19, 19, 18, 18, 18, 18, 18, 18, 17, 17, 17, 16, 16, 16, 15, 15, 15,\n",
            "        15, 15, 14, 14, 14, 14, 14, 14, 14, 13, 13, 13, 13, 13, 13, 12, 12, 12,\n",
            "        11, 11, 11, 11, 11, 10, 10,  8,  8,  5], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([35, 34, 29, 27, 26, 25, 25, 24, 24, 23, 23, 23, 22, 22, 21, 21, 20, 19,\n",
            "        19, 19, 19, 18, 18, 18, 18, 17, 17, 17, 17, 17, 17, 16, 15, 15, 15, 15,\n",
            "        15, 15, 15, 15, 14, 14, 14, 14, 13, 13, 13, 13, 12, 12, 12, 12, 11, 11,\n",
            "        11, 11, 10, 10,  9,  9,  9,  9,  7,  6], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([32, 29, 27, 26, 25, 25, 24, 24, 23, 23, 22, 21, 20, 20, 20, 19, 19, 18,\n",
            "        18, 18, 18, 18, 17, 17, 17, 16, 16, 16, 16, 15, 15, 15, 15, 15, 15, 15,\n",
            "        15, 15, 14, 14, 14, 14, 14, 13, 13, 13, 13, 13, 13, 12, 12, 12, 12, 12,\n",
            "        12, 11, 11, 11, 11, 11, 11, 10,  9,  9], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([36, 34, 29, 27, 27, 26, 26, 24, 24, 24, 23, 22, 22, 22, 21, 21, 21, 20,\n",
            "        20, 20, 19, 19, 17, 17, 17, 16, 16, 16, 16, 16, 15, 15, 15, 15, 15, 14,\n",
            "        14, 14, 13, 13, 13, 13, 13, 13, 12, 12, 12, 12, 11, 11, 11, 11, 11, 11,\n",
            "        11, 11, 10, 10, 10,  9,  9,  8,  8,  6], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([32, 30, 28, 27, 27, 27, 26, 26, 25, 24, 23, 23, 23, 23, 22, 21, 21, 20,\n",
            "        20, 19, 18, 18, 18, 18, 18, 17, 17, 17, 16, 16, 16, 16, 16, 16, 15, 15,\n",
            "        15, 15, 15, 15, 15, 14, 14, 14, 14, 14, 13, 13, 12, 12, 12, 11, 11, 11,\n",
            "        11, 11, 11, 11, 10, 10, 10,  9,  8,  7], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([55, 41, 34, 32, 31, 30, 29, 29, 28, 28, 27, 26, 25, 24, 23, 23, 22, 21,\n",
            "        21, 20, 20, 20, 20, 20, 19, 19, 19, 18, 18, 17, 17, 16, 16, 16, 16, 16,\n",
            "        16, 16, 14, 14, 14, 14, 14, 13, 13, 13, 12, 12, 12, 11, 11, 11, 11, 10,\n",
            "        10, 10, 10, 10,  9,  9,  9,  8,  8,  8], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([37, 33, 33, 32, 30, 29, 27, 26, 25, 25, 25, 25, 24, 24, 23, 23, 23, 23,\n",
            "        22, 21, 21, 21, 21, 20, 20, 20, 20, 19, 19, 19, 19, 19, 19, 18, 17, 17,\n",
            "        17, 17, 16, 16, 16, 15, 15, 14, 14, 14, 13, 13, 13, 13, 12, 12, 12, 11,\n",
            "        11, 11, 10, 10,  9,  9,  9,  9,  7,  5], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([36, 33, 32, 29, 28, 27, 26, 25, 24, 24, 23, 23, 22, 22, 21, 20, 20, 20,\n",
            "        19, 19, 19, 18, 18, 18, 18, 17, 17, 17, 17, 17, 16, 16, 16, 16, 15, 15,\n",
            "        15, 14, 14, 14, 14, 14, 14, 13, 13, 12, 12, 12, 12, 11, 11, 10, 10, 10,\n",
            "        10,  9,  9,  9,  8,  8,  8,  7,  7,  6], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([30, 28, 28, 27, 26, 25, 25, 25, 24, 22, 21, 21, 21, 21, 20, 19, 19, 18,\n",
            "        18, 18, 18, 17, 17, 16, 16, 16, 16, 16, 15, 15, 15, 15, 14, 13, 13, 13,\n",
            "        13, 12, 12, 12, 12, 12, 12, 12, 12, 11, 11, 11, 11, 10, 10, 10, 10,  9,\n",
            "         9,  9,  9,  9,  9,  8,  8,  8,  7,  7], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([33, 32, 30, 27, 27, 26, 26, 26, 25, 25, 25, 24, 24, 24, 23, 22, 21, 21,\n",
            "        21, 20, 20, 19, 18, 18, 17, 17, 17, 16, 16, 16, 16, 15, 15, 15, 15, 15,\n",
            "        15, 15, 15, 15, 14, 14, 14, 14, 14, 13, 13, 13, 13, 12, 12, 12, 11, 11,\n",
            "        11, 11, 11, 10, 10, 10,  9,  8,  8,  7], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([25, 24, 24, 24, 23, 23, 23, 22, 21, 21, 21, 21, 20, 20, 20, 20, 19, 19,\n",
            "        19, 19, 19, 18, 18, 17, 17, 16, 16, 15, 15, 15, 15, 14, 14, 14, 14, 14,\n",
            "        13, 13, 13, 13, 13, 13, 13, 12, 12, 12, 12, 12, 11, 11, 11, 11, 11, 11,\n",
            "        10,  9,  9,  9,  9,  9,  9,  8,  8,  7], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([39, 34, 29, 27, 27, 25, 25, 24, 24, 23, 23, 22, 22, 22, 22, 22, 21, 21,\n",
            "        21, 20, 20, 20, 20, 19, 19, 18, 18, 17, 17, 17, 16, 16, 16, 16, 16, 16,\n",
            "        16, 15, 15, 15, 15, 15, 15, 15, 14, 14, 14, 14, 13, 13, 12, 12, 11, 11,\n",
            "        11, 11, 11, 11, 10,  9,  9,  8,  7,  7], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([28, 26, 26, 25, 24, 23, 23, 22, 22, 22, 21, 21, 21, 20, 20, 19, 19, 18,\n",
            "        18, 18, 18, 18, 17, 17, 17, 17, 17, 17, 16, 16, 16, 16, 15, 15, 15, 15,\n",
            "        14, 14, 13, 13, 12, 12, 12, 12, 11, 11, 11, 11, 11, 11, 11, 10, 10, 10,\n",
            "        10, 10,  9,  9,  8,  8,  8,  7,  7,  7], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([45, 31, 29, 29, 26, 26, 25, 25, 25, 23, 23, 23, 22, 21, 21, 21, 21, 20,\n",
            "        20, 20, 20, 19, 19, 19, 18, 18, 18, 17, 17, 17, 17, 16, 16, 16, 15, 15,\n",
            "        15, 14, 14, 14, 14, 14, 14, 13, 12, 12, 12, 11, 11, 11, 11, 11, 10, 10,\n",
            "        10, 10,  9,  9,  9,  9,  7,  7,  7,  5], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([29, 29, 29, 28, 28, 26, 24, 24, 23, 23, 23, 22, 22, 22, 22, 21, 21, 21,\n",
            "        20, 20, 20, 19, 19, 19, 18, 18, 18, 17, 17, 16, 16, 15, 15, 14, 14, 14,\n",
            "        13, 12, 12, 12, 12, 12, 11, 11, 11, 11, 10, 10, 10, 10, 10, 10, 10,  9,\n",
            "         9,  8,  8,  8,  8,  8,  8,  8,  8,  7], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([35, 35, 33, 29, 28, 27, 26, 23, 22, 22, 22, 22, 21, 21, 20, 20, 20, 20,\n",
            "        19, 19, 19, 18, 18, 18, 17, 17, 17, 17, 16, 15, 15, 15, 15, 14, 14, 14,\n",
            "        14, 14, 13, 13, 13, 13, 12, 12, 12, 12, 12, 12, 11, 11, 11, 11, 11, 11,\n",
            "        10, 10, 10, 10,  9,  8,  8,  8,  8,  7], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([36, 32, 30, 29, 27, 27, 26, 25, 24, 24, 23, 22, 22, 22, 22, 21, 21, 21,\n",
            "        20, 20, 19, 19, 19, 19, 18, 17, 17, 17, 17, 17, 16, 16, 16, 16, 16, 16,\n",
            "        16, 16, 16, 16, 16, 15, 15, 14, 14, 14, 14, 13, 13, 13, 13, 12, 11, 11,\n",
            "        11, 11, 11, 10, 10, 10,  8,  7,  6,  6], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([47, 46, 40, 32, 32, 30, 30, 25, 25, 24, 23, 23, 22, 21, 21, 21, 20, 20,\n",
            "        19, 19, 19, 19, 18, 18, 18, 17, 17, 17, 17, 17, 16, 16, 16, 16, 16, 16,\n",
            "        16, 15, 15, 14, 14, 14, 14, 13, 13, 13, 13, 13, 12, 12, 12, 11, 11, 11,\n",
            "        10, 10, 10, 10, 10,  9,  8,  8,  8,  7], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([33, 33, 29, 29, 28, 28, 25, 25, 25, 24, 24, 24, 24, 24, 23, 22, 22, 22,\n",
            "        22, 21, 20, 19, 19, 19, 18, 18, 18, 18, 17, 17, 16, 16, 16, 16, 16, 15,\n",
            "        15, 15, 14, 14, 13, 13, 13, 13, 13, 13, 12, 12, 12, 12, 11, 11, 11, 11,\n",
            "        10, 10, 10, 10,  9,  9,  9,  9,  8,  8], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([38, 27, 27, 26, 25, 24, 24, 23, 23, 22, 22, 22, 21, 21, 21, 20, 20, 20,\n",
            "        20, 19, 19, 19, 19, 19, 18, 18, 17, 17, 17, 17, 17, 16, 16, 16, 15, 15,\n",
            "        14, 13, 13, 12, 12, 12, 12, 12, 11, 11, 11, 11, 11, 11, 11, 10, 10, 10,\n",
            "        10, 10,  9,  9,  9,  9,  9,  8,  8,  7], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([45, 32, 31, 28, 28, 28, 27, 26, 24, 23, 22, 21, 20, 20, 20, 20, 19, 19,\n",
            "        19, 19, 18, 18, 18, 18, 18, 18, 17, 17, 17, 17, 17, 17, 16, 16, 16, 16,\n",
            "        15, 15, 15, 15, 15, 15, 14, 13, 13, 13, 13, 13, 13, 12, 12, 12, 12, 12,\n",
            "        12, 12, 12, 12, 11, 11, 10, 10,  9,  9], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([40, 38, 32, 30, 29, 28, 27, 26, 25, 25, 25, 24, 24, 24, 23, 23, 23, 23,\n",
            "        23, 23, 23, 21, 20, 20, 20, 20, 20, 19, 19, 19, 19, 18, 18, 18, 18, 18,\n",
            "        18, 17, 17, 17, 17, 16, 16, 16, 15, 14, 13, 13, 13, 13, 13, 13, 12, 12,\n",
            "        11, 11, 11, 10, 10, 10,  9,  9,  8,  8], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([34, 33, 32, 32, 31, 29, 28, 28, 27, 25, 24, 24, 23, 23, 22, 22, 22, 22,\n",
            "        22, 22, 21, 21, 20, 20, 20, 20, 19, 19, 19, 18, 18, 18, 17, 17, 17, 16,\n",
            "        15, 15, 15, 15, 15, 15, 15, 14, 14, 14, 14, 14, 13, 12, 12, 12, 11, 11,\n",
            "        11, 10, 10,  9,  9,  9,  9,  9,  7,  6], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([45, 36, 35, 30, 28, 28, 25, 23, 22, 22, 21, 21, 21, 21, 19, 19, 19, 19,\n",
            "        19, 18, 18, 18, 18, 17, 17, 16, 16, 16, 16, 15, 15, 15, 15, 14, 14, 14,\n",
            "        14, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 12, 12, 12, 12, 11, 11, 11,\n",
            "        11, 10,  9,  9,  9,  8,  8,  7,  7,  6], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([39, 39, 34, 32, 31, 31, 31, 26, 24, 24, 23, 23, 23, 23, 22, 21, 21, 21,\n",
            "        21, 20, 20, 20, 19, 19, 19, 19, 19, 18, 17, 17, 17, 17, 17, 17, 17, 16,\n",
            "        16, 16, 16, 15, 15, 15, 14, 14, 14, 13, 13, 12, 12, 12, 11, 11, 11, 11,\n",
            "        11, 10, 10, 10, 10, 10, 10,  9,  8,  8], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([31, 28, 28, 27, 26, 25, 25, 24, 22, 22, 22, 22, 22, 22, 21, 21, 21, 20,\n",
            "        20, 20, 19, 19, 18, 18, 18, 18, 18, 17, 17, 17, 17, 16, 16, 15, 15, 15,\n",
            "        14, 14, 14, 14, 13, 13, 13, 13, 13, 12, 12, 12, 12, 12, 11, 11, 10, 10,\n",
            "        10, 10, 10, 10, 10, 10,  9,  9,  9,  7], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([35, 31, 29, 28, 28, 24, 24, 23, 22, 22, 21, 21, 20, 19, 19, 19, 19, 19,\n",
            "        19, 18, 18, 18, 18, 17, 17, 16, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
            "        14, 14, 14, 14, 13, 13, 13, 12, 12, 12, 11, 11, 11, 11, 11, 10, 10, 10,\n",
            "         9,  9,  9,  9,  9,  9,  9,  9,  7,  7], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([35, 28, 28, 28, 26, 26, 25, 23, 23, 23, 23, 23, 23, 23, 22, 22, 22, 22,\n",
            "        21, 21, 20, 20, 20, 20, 19, 19, 18, 18, 18, 18, 18, 17, 17, 16, 16, 16,\n",
            "        16, 15, 15, 15, 15, 14, 14, 13, 13, 13, 13, 12, 12, 12, 11, 11, 11, 11,\n",
            "        10,  9,  9,  9,  9,  9,  8,  8,  7,  7], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([27, 26, 25, 25, 24, 24, 23, 23, 22, 22, 21, 21, 21, 20, 20, 19, 19, 19,\n",
            "        19, 18, 18, 18, 18, 17, 17, 17, 17, 17, 16, 16, 16, 15, 15, 15, 14, 14,\n",
            "        14, 14, 14, 14, 14, 13, 13, 13, 12, 12, 12, 11, 11, 11, 11, 10, 10, 10,\n",
            "        10, 10, 10, 10,  9,  9,  9,  9,  9,  4], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([40, 38, 37, 33, 28, 26, 26, 25, 24, 24, 24, 24, 22, 21, 21, 21, 19, 19,\n",
            "        18, 18, 18, 17, 17, 17, 17, 17, 17, 17, 17, 16, 16, 16, 16, 15, 15, 15,\n",
            "        14, 14, 14, 14, 14, 14, 14, 13, 13, 12, 12, 12, 11, 11, 10, 10, 10, 10,\n",
            "         9,  9,  9,  9,  9,  9,  8,  8,  7,  7], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([39, 34, 32, 30, 29, 27, 26, 25, 25, 25, 25, 24, 24, 23, 23, 22, 22, 21,\n",
            "        21, 21, 20, 20, 19, 19, 19, 19, 18, 18, 17, 17, 17, 17, 17, 16, 16, 16,\n",
            "        16, 16, 16, 15, 15, 15, 15, 14, 14, 14, 13, 13, 13, 13, 12, 12, 12, 12,\n",
            "        12, 10, 10, 10,  9,  9,  8,  8,  7,  7], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([33, 29, 28, 27, 26, 26, 25, 24, 23, 23, 23, 22, 22, 22, 22, 21, 21, 21,\n",
            "        20, 20, 20, 20, 19, 19, 18, 18, 17, 17, 17, 17, 16, 16, 16, 15, 15, 15,\n",
            "        15, 15, 15, 15, 14, 14, 14, 14, 14, 14, 13, 13, 13, 12, 12, 11, 11, 11,\n",
            "        11, 11, 10, 10, 10, 10, 10,  8,  8,  8], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([38, 31, 30, 29, 26, 26, 25, 24, 23, 22, 22, 22, 22, 22, 21, 21, 20, 20,\n",
            "        19, 19, 19, 19, 18, 18, 18, 17, 17, 17, 16, 16, 16, 16, 16, 15, 15, 15,\n",
            "        15, 14, 14, 14, 14, 13, 13, 13, 13, 12, 12, 12, 12, 12, 11, 11, 11, 11,\n",
            "        10, 10, 10, 10,  9,  9,  9,  7,  7,  7], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([35, 31, 30, 28, 27, 27, 26, 26, 25, 25, 21, 21, 20, 19, 19, 19, 19, 19,\n",
            "        19, 19, 19, 18, 18, 18, 17, 17, 17, 17, 17, 17, 16, 16, 16, 16, 16, 15,\n",
            "        15, 14, 14, 14, 14, 14, 13, 13, 13, 13, 13, 13, 12, 12, 12, 12, 11, 11,\n",
            "        11, 10, 10,  9,  9,  8,  8,  8,  8,  6], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([41, 30, 26, 25, 24, 23, 23, 22, 22, 22, 22, 21, 21, 21, 20, 19, 19, 18,\n",
            "        18, 18, 18, 18, 17, 17, 17, 16, 16, 16, 16, 16, 15, 15, 15, 14, 14, 14,\n",
            "        14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 12, 12, 12, 12, 12, 12, 11, 11,\n",
            "        11, 10, 10, 10, 10, 10,  9,  8,  8,  7], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([35, 33, 32, 29, 29, 27, 26, 26, 24, 24, 23, 23, 22, 21, 21, 20, 20, 20,\n",
            "        20, 18, 18, 18, 17, 17, 17, 16, 16, 16, 16, 16, 16, 15, 15, 15, 15, 14,\n",
            "        14, 14, 14, 13, 13, 13, 13, 13, 13, 13, 11, 11, 11, 11, 11, 11, 10, 10,\n",
            "        10, 10, 10, 10,  9,  9,  9,  9,  8,  7], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([38, 36, 35, 32, 30, 28, 27, 27, 26, 26, 26, 24, 24, 23, 22, 22, 22, 21,\n",
            "        21, 21, 20, 20, 20, 19, 19, 19, 19, 19, 18, 18, 18, 18, 18, 18, 18, 17,\n",
            "        17, 17, 17, 17, 16, 16, 15, 15, 15, 14, 14, 14, 14, 14, 14, 13, 13, 13,\n",
            "        13, 11, 11, 11, 11, 10, 10,  9,  9,  9], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([44, 32, 31, 31, 30, 29, 28, 26, 25, 25, 24, 23, 22, 22, 22, 22, 21, 21,\n",
            "        21, 20, 20, 19, 18, 18, 17, 17, 17, 17, 17, 16, 16, 15, 15, 15, 15, 15,\n",
            "        14, 14, 14, 14, 14, 14, 13, 13, 13, 13, 13, 12, 12, 12, 12, 12, 11, 10,\n",
            "        10, 10, 10,  9,  9,  9,  8,  7,  7,  7], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([61, 51, 29, 28, 28, 27, 26, 26, 26, 25, 24, 24, 24, 23, 23, 23, 22, 22,\n",
            "        21, 21, 20, 20, 20, 19, 19, 19, 19, 19, 19, 19, 18, 18, 18, 17, 17, 16,\n",
            "        16, 16, 16, 15, 15, 15, 14, 14, 14, 13, 13, 13, 12, 12, 12, 11, 11, 11,\n",
            "        11, 11, 10, 10,  9,  9,  9,  8,  8,  6], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([30, 29, 28, 25, 25, 25, 25, 25, 24, 23, 23, 23, 23, 23, 22, 22, 21, 21,\n",
            "        21, 21, 21, 20, 20, 19, 19, 19, 18, 18, 17, 17, 17, 17, 16, 16, 16, 16,\n",
            "        15, 15, 14, 14, 14, 14, 13, 12, 12, 12, 12, 11, 11, 11, 11, 10, 10, 10,\n",
            "        10, 10,  9,  9,  8,  8,  8,  6,  6,  5], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([36, 33, 31, 27, 27, 26, 26, 26, 25, 25, 24, 24, 24, 23, 23, 23, 23, 22,\n",
            "        22, 22, 21, 21, 21, 21, 20, 19, 19, 18, 18, 18, 17, 17, 16, 16, 15, 15,\n",
            "        15, 15, 15, 14, 14, 14, 14, 13, 13, 13, 13, 12, 12, 12, 12, 11, 11, 11,\n",
            "        11, 10, 10, 10,  9,  9,  8,  8,  8,  8], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([36, 34, 33, 28, 28, 27, 25, 24, 23, 23, 23, 23, 23, 23, 23, 22, 22, 21,\n",
            "        21, 21, 20, 20, 20, 19, 19, 19, 19, 18, 18, 18, 18, 17, 16, 16, 16, 16,\n",
            "        16, 16, 16, 15, 15, 15, 15, 15, 15, 14, 13, 13, 13, 12, 12, 12, 12, 12,\n",
            "        12, 11, 11, 10, 10, 10,  9,  8,  7,  7], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([42, 33, 32, 29, 29, 28, 26, 25, 25, 25, 24, 24, 23, 22, 22, 22, 21, 21,\n",
            "        21, 21, 20, 19, 19, 19, 18, 18, 18, 18, 18, 17, 16, 16, 16, 16, 16, 15,\n",
            "        15, 15, 14, 14, 14, 14, 14, 14, 14, 13, 13, 13, 13, 13, 13, 13, 12, 12,\n",
            "        12, 11, 10, 10, 10, 10,  9,  8,  8,  7], device='cuda:0')\n",
            "torch.Size([64, 61, 768])\n",
            "shape sorted.. tensor([32, 31, 30, 30, 28, 27, 27, 26, 25, 24, 24, 23, 23, 23, 22, 22, 21, 21,\n",
            "        20, 20, 20, 20, 19, 19, 19, 18, 18, 18, 18, 18, 18, 17, 17, 16, 16, 16,\n",
            "        16, 16, 15, 15, 15, 15, 14, 13, 13, 13, 13, 13, 12, 12, 11, 11, 11, 11,\n",
            "        11, 11, 10, 10, 10,  9,  9,  9,  8,  7], device='cuda:0')\n",
            "torch.Size([8, 61, 768])\n",
            "shape sorted.. tensor([29, 28, 22, 16, 15, 13, 11,  8], device='cuda:0')\n",
            "torch.Size([64, 85, 768])\n",
            "shape sorted.. tensor([37, 35, 33, 32, 27, 27, 27, 26, 25, 23, 23, 23, 22, 22, 22, 21, 21, 20,\n",
            "        20, 20, 20, 20, 20, 19, 19, 18, 18, 17, 17, 17, 17, 17, 16, 16, 16, 16,\n",
            "        16, 16, 15, 15, 14, 14, 14, 13, 13, 13, 13, 12, 12, 12, 12, 12, 11, 11,\n",
            "        11, 11, 10, 10,  9,  9,  9,  9,  9,  8], device='cuda:0')\n",
            "torch.Size([64, 17, 768])\n",
            "shape sorted.. tensor([14, 13, 13, 13, 13, 11, 11, 10, 10, 10,  8,  8,  8,  8,  8,  8,  8,  8,\n",
            "         7,  7,  7,  7,  7,  7,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
            "         6,  6,  6,  6,  6,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
            "         5,  5,  5,  5,  4,  4,  4,  4,  4,  4], device='cuda:0')\n",
            "torch.Size([64, 49, 1792])\n",
            "shape sorted.. tensor([40, 37, 37, 37, 37, 31, 31, 28, 28, 28, 22, 22, 22, 22, 22, 22, 22, 22,\n",
            "        19, 19, 19, 19, 19, 19, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
            "        16, 16, 16, 16, 16, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
            "        13, 13, 13, 13, 10, 10, 10, 10, 10, 10], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-06-17 03:13:02,883 INFO     input_dir:./processed/\n",
            "2023-06-17 03:13:02,883 INFO     save_dir:./checkpoint\n",
            "2023-06-17 03:13:02,883 INFO     glove_pt:./glove/glove_merged.pkl\n",
            "2023-06-17 03:13:02,883 INFO     ckpt:None\n",
            "2023-06-17 03:13:02,883 INFO     lr:0.001\n",
            "2023-06-17 03:13:02,883 INFO     weight_decay:1e-05\n",
            "2023-06-17 03:13:02,883 INFO     num_epoch:1\n",
            "2023-06-17 03:13:02,884 INFO     batch_size:64\n",
            "2023-06-17 03:13:02,884 INFO     seed:666\n",
            "2023-06-17 03:13:02,884 INFO     dim_word:300\n",
            "2023-06-17 03:13:02,884 INFO     dim_hidden:1024\n",
            "2023-06-17 03:13:02,937 INFO     Create train_loader and val_loader.........\n",
            "2023-06-17 03:13:08,303 INFO     Create model.........\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "2023-06-17 03:13:12,129 INFO     Load pretrained word vectors.........\n",
            "2023-06-17 03:13:43,118 INFO     Parser(\n",
            "  (model): DistilBertModel(\n",
            "    (embeddings): Embeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (transformer): Transformer(\n",
            "      (layer): ModuleList(\n",
            "        (0-5): 6 x TransformerBlock(\n",
            "          (attention): MultiHeadSelfAttention(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (ffn): FFN(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (activation): GELUActivation()\n",
            "          )\n",
            "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (word_embeddings): Embedding(80201, 768)\n",
            "  (word_dropout): Dropout(p=0.2, inplace=False)\n",
            "  (question_encoder): GRU(\n",
            "    (encoder): GRU(768, 1024, num_layers=2, batch_first=True, dropout=0.2)\n",
            "  )\n",
            "  (func_embeddings): Embedding(31, 768)\n",
            "  (decoder): GRU(\n",
            "    (encoder): GRU(768, 1024, num_layers=2, batch_first=True, dropout=0.2)\n",
            "  )\n",
            "  (func_classifier): Sequential(\n",
            "    (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=1024, out_features=31, bias=True)\n",
            "  )\n",
            "  (inp_embeddings): Embedding(80201, 768)\n",
            "  (inp_decoder): GRU(\n",
            "    (encoder): GRU(1792, 1024, num_layers=2, batch_first=True, dropout=0.2)\n",
            "  )\n",
            "  (inp_classifier): Sequential(\n",
            "    (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=1024, out_features=80201, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "  0%|          | 0/79 [00:00<?, ?it/s]\n",
            "  1%|▏         | 1/79 [00:01<01:37,  1.24s/it]\n",
            "  3%|▎         | 2/79 [00:02<01:14,  1.03it/s]\n",
            "  4%|▍         | 3/79 [00:02<01:07,  1.13it/s]\n",
            "  5%|▌         | 4/79 [00:03<01:03,  1.18it/s]\n",
            "  6%|▋         | 5/79 [00:04<01:01,  1.20it/s]\n",
            "  8%|▊         | 6/79 [00:05<00:59,  1.22it/s]\n",
            "  9%|▉         | 7/79 [00:05<00:58,  1.23it/s]\n",
            " 10%|█         | 8/79 [00:06<00:57,  1.24it/s]\n",
            " 11%|█▏        | 9/79 [00:07<00:56,  1.25it/s]\n",
            " 13%|█▎        | 10/79 [00:08<00:54,  1.26it/s]\n",
            " 14%|█▍        | 11/79 [00:09<00:53,  1.26it/s]\n",
            " 15%|█▌        | 12/79 [00:09<00:52,  1.27it/s]\n",
            " 16%|█▋        | 13/79 [00:10<00:52,  1.26it/s]\n",
            " 18%|█▊        | 14/79 [00:11<00:51,  1.27it/s]\n",
            " 19%|█▉        | 15/79 [00:12<00:50,  1.26it/s]\n",
            " 20%|██        | 16/79 [00:13<00:49,  1.26it/s]\n",
            " 22%|██▏       | 17/79 [00:13<00:49,  1.26it/s]\n",
            " 23%|██▎       | 18/79 [00:14<00:48,  1.26it/s]\n",
            " 24%|██▍       | 19/79 [00:15<00:47,  1.26it/s]\n",
            " 25%|██▌       | 20/79 [00:16<00:46,  1.26it/s]\n",
            " 27%|██▋       | 21/79 [00:17<00:46,  1.25it/s]\n",
            " 28%|██▊       | 22/79 [00:17<00:45,  1.26it/s]\n",
            " 29%|██▉       | 23/79 [00:18<00:44,  1.26it/s]\n",
            " 30%|███       | 24/79 [00:19<00:44,  1.25it/s]\n",
            " 32%|███▏      | 25/79 [00:20<00:43,  1.25it/s]\n",
            " 33%|███▎      | 26/79 [00:21<00:42,  1.25it/s]\n",
            " 34%|███▍      | 27/79 [00:21<00:41,  1.25it/s]\n",
            " 35%|███▌      | 28/79 [00:22<00:40,  1.25it/s]\n",
            " 37%|███▋      | 29/79 [00:23<00:40,  1.25it/s]\n",
            " 38%|███▊      | 30/79 [00:24<00:39,  1.26it/s]\n",
            " 39%|███▉      | 31/79 [00:25<00:38,  1.25it/s]\n",
            " 41%|████      | 32/79 [00:25<00:37,  1.25it/s]\n",
            " 42%|████▏     | 33/79 [00:26<00:36,  1.27it/s]\n",
            " 43%|████▎     | 34/79 [00:27<00:35,  1.26it/s]\n",
            " 44%|████▍     | 35/79 [00:28<00:34,  1.27it/s]\n",
            " 46%|████▌     | 36/79 [00:29<00:33,  1.27it/s]\n",
            " 47%|████▋     | 37/79 [00:29<00:33,  1.27it/s]\n",
            " 48%|████▊     | 38/79 [00:30<00:32,  1.27it/s]\n",
            " 49%|████▉     | 39/79 [00:31<00:31,  1.26it/s]\n",
            " 51%|█████     | 40/79 [00:32<00:30,  1.26it/s]\n",
            " 52%|█████▏    | 41/79 [00:33<00:30,  1.25it/s]\n",
            " 53%|█████▎    | 42/79 [00:33<00:29,  1.25it/s]\n",
            " 54%|█████▍    | 43/79 [00:34<00:28,  1.26it/s]\n",
            " 56%|█████▌    | 44/79 [00:35<00:27,  1.26it/s]\n",
            " 57%|█████▋    | 45/79 [00:36<00:26,  1.27it/s]\n",
            " 58%|█████▊    | 46/79 [00:36<00:26,  1.26it/s]\n",
            " 59%|█████▉    | 47/79 [00:37<00:25,  1.26it/s]\n",
            " 61%|██████    | 48/79 [00:38<00:24,  1.26it/s]\n",
            " 62%|██████▏   | 49/79 [00:39<00:23,  1.27it/s]\n",
            " 63%|██████▎   | 50/79 [00:40<00:22,  1.27it/s]\n",
            " 65%|██████▍   | 51/79 [00:40<00:22,  1.26it/s]\n",
            " 66%|██████▌   | 52/79 [00:41<00:21,  1.26it/s]\n",
            " 67%|██████▋   | 53/79 [00:42<00:20,  1.26it/s]\n",
            " 68%|██████▊   | 54/79 [00:43<00:19,  1.26it/s]\n",
            " 70%|██████▉   | 55/79 [00:44<00:18,  1.26it/s]\n",
            " 71%|███████   | 56/79 [00:44<00:18,  1.26it/s]\n",
            " 72%|███████▏  | 57/79 [00:45<00:17,  1.26it/s]\n",
            " 73%|███████▎  | 58/79 [00:46<00:16,  1.26it/s]\n",
            " 75%|███████▍  | 59/79 [00:47<00:16,  1.25it/s]\n",
            " 76%|███████▌  | 60/79 [00:48<00:15,  1.25it/s]\n",
            " 77%|███████▋  | 61/79 [00:48<00:14,  1.26it/s]\n",
            " 78%|███████▊  | 62/79 [00:49<00:13,  1.25it/s]\n",
            " 80%|███████▉  | 63/79 [00:50<00:12,  1.26it/s]\n",
            " 81%|████████  | 64/79 [00:51<00:11,  1.26it/s]\n",
            " 82%|████████▏ | 65/79 [00:52<00:11,  1.26it/s]\n",
            " 84%|████████▎ | 66/79 [00:52<00:10,  1.26it/s]\n",
            " 85%|████████▍ | 67/79 [00:53<00:09,  1.25it/s]\n",
            " 86%|████████▌ | 68/79 [00:54<00:08,  1.26it/s]\n",
            " 87%|████████▋ | 69/79 [00:55<00:07,  1.26it/s]\n",
            " 89%|████████▊ | 70/79 [00:56<00:07,  1.25it/s]\n",
            " 90%|████████▉ | 71/79 [00:56<00:06,  1.24it/s]\n",
            " 91%|█████████ | 72/79 [00:57<00:05,  1.25it/s]\n",
            " 92%|█████████▏| 73/79 [00:58<00:04,  1.25it/s]\n",
            " 94%|█████████▎| 74/79 [00:59<00:04,  1.25it/s]\n",
            " 95%|█████████▍| 75/79 [01:00<00:03,  1.25it/s]\n",
            " 96%|█████████▌| 76/79 [01:00<00:02,  1.26it/s]\n",
            " 97%|█████████▋| 77/79 [01:01<00:01,  1.25it/s]\n",
            " 99%|█████████▊| 78/79 [01:02<00:00,  1.25it/s]\n",
            "100%|██████████| 79/79 [01:02<00:00,  1.51it/s]\n",
            "100%|██████████| 79/79 [01:02<00:00,  1.26it/s]\n",
            "2023-06-17 03:14:45,905 INFO     \n",
            "Valid match program: 0.0000, inputs: 0.0000\n",
            "\n",
            "2023-06-17 03:14:45,906 INFO     Start training........\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\Adrian Segura\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"c:\\Users\\Adrian Segura\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"c:\\Users\\Adrian Segura\\Desktop\\TUDelft\\Q4\\KQAPro_Baselines\\Program\\train.py\", line 212, in <module>\n",
            "    main()\n",
            "  File \"c:\\Users\\Adrian Segura\\Desktop\\TUDelft\\Q4\\KQAPro_Baselines\\Program\\train.py\", line 208, in main\n",
            "    train(args)\n",
            "  File \"c:\\Users\\Adrian Segura\\Desktop\\TUDelft\\Q4\\KQAPro_Baselines\\Program\\train.py\", line 143, in train\n",
            "    loss = model(question, program, prog_inputs)\n",
            "  File \"c:\\Users\\Adrian Segura\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"c:\\Users\\Adrian Segura\\Desktop\\TUDelft\\Q4\\KQAPro_Baselines\\Program\\parser.py\", line 101, in forward\n",
            "    return self.train_phase(q_word_h, q_embeddings, q_hn, programs, inputs)\n",
            "  File \"c:\\Users\\Adrian Segura\\Desktop\\TUDelft\\Q4\\KQAPro_Baselines\\Program\\parser.py\", line 144, in train_phase\n",
            "    loss_inp = criterion_CE(logit_inp.permute(0, 2, 1)[:,:,:-1], inputs[:,1:]) # shift the input <START>\n",
            "  File \"c:\\Users\\Adrian Segura\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"c:\\Users\\Adrian Segura\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py\", line 1174, in forward\n",
            "    return F.cross_entropy(input, target, weight=self.weight,\n",
            "  File \"c:\\Users\\Adrian Segura\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\", line 3029, in cross_entropy\n",
            "    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 940.00 MiB (GPU 0; 6.00 GiB total capacity; 5.06 GiB already allocated; 0 bytes free; 5.27 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
          ]
        }
      ],
      "source": [
        "!python -m Program.train --input_dir ./processed/ --save_dir ./checkpoint --glove_pt ./glove/glove_merged.pkl --num_epoch 1 --batch_size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "fo = open(\"./checkpoint/log.txt\", \"wb\")\n",
        "\n",
        "# Close opend file\n",
        "fo.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "KURPmAnV-TXs",
        "outputId": "e69ddeca-cbd8-495e-c96b-f239d84dd624"
      },
      "outputs": [
        {
          "ename": "EOFError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-3335fb3a0b41>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./glove/glove.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "with open(\"./glove/glove.pkl\", 'rb') as f:\n",
        "    d = pickle.load(f)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ivEa74d27qjX"
      },
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "28pX89xIGGGO"
      },
      "source": [
        "# NSM\n",
        "Here we attempt to train a NSM following the repository: https://github.com/RichardHGL/WSDM2021_NSM"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "T2YLiuPCGbfU"
      },
      "source": [
        "## Loading pre-processed data\n",
        "The authors provide files for the WebQSP dataset, already pre-processed to be used to train the Neural State Machine depicted in their paper: https://arxiv.org/pdf/2101.03737.pdf\n",
        "\n",
        "As mentioned in the repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZDFZFUjFaA7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "c33a5a251ac0a50bb54cdb44463ca91c892db7e13767376952a9716cba18aa10"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
